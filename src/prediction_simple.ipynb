{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2b5b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe27842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/manu/Desktop/SUP/Projet 2/AI_model_urban_mobility/data/df_final_15min_NoNan_20250505.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114b740",
   "metadata": {},
   "source": [
    "# Gestion des données temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55617827",
   "metadata": {},
   "source": [
    "Création de profils temporels : des profils regroupant des créneaux horaires similaires selon le jour, l’heure, les vacances et les jours fériés pour chaque tronçon. Ça permet de capturer les habitudes de trafic à différents moments de la semaine.\n",
    "\n",
    "En ajoutant ces profils au modèle, on aide la prédiction à mieux comprendre comment le trafic change selon le temps et le lieu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8b3d6",
   "metadata": {},
   "source": [
    "## Calcul des moyennes horaires par tronçon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433e630",
   "metadata": {},
   "source": [
    "Création d'une variable quarter_hour qui identifie chaque créneau de 15 minutes dans la journée, afin de capturer plus finement la variation temporelle du trafic dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946242ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarter_hour'] = df['hour'] * 4 + df['minute'] // 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf6ba6",
   "metadata": {},
   "source": [
    "## Touver le nombre de cluster ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9287d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(df_t, max_k=10):\n",
    "    X = df_t[['weekday', 'quarter_hour', 'is_vacances', 'is_ferie']].copy()\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    best_score = -1\n",
    "    best_k = 2\n",
    "\n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        labels = kmeans.fit_predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec327777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recherche de k optimal:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recherche de k optimal: 100%|██████████| 200/200 [03:27<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre optimal de clusters trouvé sur 200 tronçons : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Application sur un echantillon de 200 tronçons aléatoire\n",
    "troncons_sample = np.random.choice(df['troncon_enc'].unique(), size=200, replace=False)\n",
    "k_list = []\n",
    "\n",
    "for troncon in tqdm(troncons_sample, desc=\"Recherche de k optimal\"):\n",
    "    df_t = df[df['troncon_enc'] == troncon]\n",
    "    if len(df_t) >= 10: \n",
    "        k_opt = find_best_k(df_t, max_k=10)\n",
    "        k_list.append(k_opt)\n",
    "\n",
    "# Trouver la valeur la plus fréquente\n",
    "mode_k = Counter(k_list).most_common(1)[0][0]\n",
    "print(f\"Nombre optimal de clusters trouvé sur 200 tronçons : {mode_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4f80f",
   "metadata": {},
   "source": [
    "## Aggrégation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c94eaec",
   "metadata": {},
   "source": [
    "Réduit la granularité temporelle et avoir des profils plus stables et moins bruités, ce qui facilite le clustering et donne des clusters plus représentatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce096fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df.groupby(['troncon_enc', 'weekday', 'quarter_hour', 'is_vacances', 'is_ferie']).agg({\n",
    "    'code_couleur': 'mean'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b3a65",
   "metadata": {},
   "source": [
    "## Application du clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c66f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_time_clusters(df_agg, n_clusters):\n",
    "    all_clusters = []\n",
    "\n",
    "    for troncon in tqdm(df_agg['troncon_enc'].unique(), desc=\"Clustering final par tronçon\"):\n",
    "        df_t = df_agg[df_agg['troncon_enc'] == troncon].copy()\n",
    "        X = df_t[['weekday', 'quarter_hour', 'is_vacances', 'is_ferie']]\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "        df_t['time_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "        all_clusters.append(df_t)\n",
    "\n",
    "    return pd.concat(all_clusters, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51b4c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering final par tronçon: 100%|██████████| 749/749 [00:09<00:00, 78.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Application sur les données agrégées\n",
    "df_clusters = compute_final_time_clusters(agg, n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206f9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sur les colonnes clés temporelles et tronçon\n",
    "df_final = df.merge(\n",
    "    df_clusters[['troncon_enc', 'weekday', 'quarter_hour', 'is_vacances', 'is_ferie', 'time_cluster']],\n",
    "    on=['troncon_enc', 'weekday', 'quarter_hour', 'is_vacances', 'is_ferie'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6d12f",
   "metadata": {},
   "source": [
    "## Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "918b9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880739\n",
      "1880739\n"
     ]
    }
   ],
   "source": [
    "print(len(df_final))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2dacd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>troncon_enc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [troncon_enc, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compter le nombre de lignes par tronçon\n",
    "count_per_troncon = df_final.groupby('troncon_enc').size().reset_index(name='count')\n",
    "count_per_troncon.loc[count_per_troncon['count'] != 2511]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ddd90",
   "metadata": {},
   "source": [
    "# Gestion des données météo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76b38044",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_vars = ['temperature_2m', 'visibility', 'precipitation', 'wind_speed_10m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe6d0839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_2m    0\n",
      "visibility        0\n",
      "precipitation     0\n",
      "wind_speed_10m    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vérification valeur manquante\n",
    "print(df_final[meteo_vars].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de244b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs négatives dans precipitation : 0\n",
      "Valeurs négatives dans wind_speed_10m : 0\n",
      "Valeurs négatives dans visibility : 0\n"
     ]
    }
   ],
   "source": [
    "# Vérification valeur negatives ou impossibles\n",
    "for var in ['precipitation', 'wind_speed_10m', 'visibility']:\n",
    "    print(f\"Valeurs négatives dans {var} : {(df_final[var] < 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3abea853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_2m min : 0.3305, max : 18.130499\n",
      "visibility min : 2160.0, max : 24140.0\n",
      "precipitation min : 0.0, max : 5.1\n",
      "wind_speed_10m min : 0.8049845, max : 33.127823\n"
     ]
    }
   ],
   "source": [
    "# Vérification valeur extreme\n",
    "for var in meteo_vars:\n",
    "    print(f\"{var} min : {df_final[var].min()}, max : {df_final[var].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_2m nombre de valeurs uniques : 270\n",
      "visibility nombre de valeurs uniques : 60\n",
      "precipitation nombre de valeurs uniques : 26\n",
      "wind_speed_10m nombre de valeurs uniques : 446\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la variabilité (ce n'est pas toujours la mm valeur qui revient)\n",
    "for var in meteo_vars:\n",
    "    print(f\"{var} nombre de valeurs uniques : {df_final[var].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a52193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precipitation = 0 dans 1728692 lignes soit 91.92%\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la présennce de pluie\n",
    "for var in ['precipitation']:\n",
    "    zeros = (df_final[var] == 0).sum()\n",
    "    total = len(df_final)\n",
    "    print(f\"{var} = 0 dans {zeros} lignes soit {zeros/total:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af737fec",
   "metadata": {},
   "source": [
    "Conclusion : Les variables météo ne contiennent aucune valeur manquante, ce qui est un bon point pour la qualité des données. Les valeurs extrêmes observées sont dans des plages réalistes pour la région considérée (ex. température entre 0,33°C et 18,13°C, précipitations jusqu’à 5,1 mm sur un quart d’heure).\n",
    "\n",
    "La précipitation est à zéro dans environ 92 % des cas, ce qui est logique car il ne pleut pas tout le temps, mais cela signifie que cette variable peut avoir un impact limité dans certains cas.\n",
    "\n",
    "Dans l’ensemble, les données météo semblent propres et exploitables directement dans le modèle sans nettoyage particulier, mais il faudra surveiller l’impact des variables avec peu de variabilité comme la précipitation souvent nulle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ea134",
   "metadata": {},
   "source": [
    "# Vérification des corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84646e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables les plus corrélées avec code_couleur :\n",
      "taux_occupation      0.819590\n",
      "temps_de_parcours    0.282691\n",
      "vitesse              0.269315\n",
      "debit                0.212483\n",
      "quarter_hour         0.044439\n",
      "hour                 0.044235\n",
      "temperature_2m       0.039239\n",
      "weekday              0.032252\n",
      "wind_speed_10m       0.030965\n",
      "is_vacances          0.030756\n",
      "troncon_enc          0.026609\n",
      "code_no2             0.025660\n",
      "time_cluster         0.008434\n",
      "longueur             0.008411\n",
      "minute               0.005995\n",
      "code_pm25            0.004685\n",
      "code_qual            0.004033\n",
      "precipitation        0.002983\n",
      "code_pm10            0.002673\n",
      "visibility           0.000523\n",
      "is_ferie                  NaN\n",
      "code_zone                 NaN\n",
      "code_so2                  NaN\n",
      "code_o3                   NaN\n",
      "x_wgs84                   NaN\n",
      "y_wgs84                   NaN\n",
      "x_reg                     NaN\n",
      "y_reg                     NaN\n",
      "epsg_reg                  NaN\n",
      "geo_point_2d_lon          NaN\n",
      "geo_point_2d_lat          NaN\n",
      "Name: code_couleur, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculer la corrélation de Pearson entre toutes les variables numériques et 'code_couleur'\n",
    "corr_matrix = df_final.select_dtypes('number').corr()\n",
    "\n",
    "# Extraire la corrélation avec 'code_couleur' et trier par valeur absolue décroissante\n",
    "corr_with_target = corr_matrix['code_couleur'].drop('code_couleur').abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Variables les plus corrélées avec code_couleur :\")\n",
    "print(corr_with_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ce951",
   "metadata": {},
   "source": [
    "Les variables les plus corrélées au trafic sont nos 4 variables temporelles. Mise de côté, on s'aperçoit que quarter_hour est la variable suivante la plus corrélée, bien plus que notre variable de clustering time_cluster. Deux modèles seront testés : 1 - avec le clustering 2 - sans le clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
