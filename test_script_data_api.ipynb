{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from -r requirement.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: psycopg==3.2.4 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from psycopg[binary]==3.2.4->-r requirement.txt (line 2)) (3.2.4)\n",
      "Requirement already satisfied: requests==2.32.3 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from -r requirement.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from pandas==2.2.3->-r requirement.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from pandas==2.2.3->-r requirement.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from pandas==2.2.3->-r requirement.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from pandas==2.2.3->-r requirement.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from psycopg==3.2.4->psycopg[binary]==3.2.4->-r requirement.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from requests==2.32.3->-r requirement.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from requests==2.32.3->-r requirement.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from requests==2.32.3->-r requirement.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from requests==2.32.3->-r requirement.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: psycopg-binary==3.2.4 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from psycopg[binary]==3.2.4->-r requirement.txt (line 2)) (3.2.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\sup_de_vinci\\ai_model_urban_mobility\\projet_etude\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirement.txt (line 1)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Récupération des secrets depuis les variables d'environnement\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "\n",
    "# Connexion a la base Azure postgresql\n",
    "def get_connection_uri():\n",
    "\n",
    "    # Read URI parameters from the environment\n",
    "    dbhost = DB_HOST\n",
    "    dbname = DB_NAME\n",
    "    dbuser = DB_USER\n",
    "    password = DB_PASSWORD\n",
    "    sslmode = 'require'\n",
    "    db_uri = f\"host={dbhost} dbname={dbname} user={dbuser} password={password} sslmode ={sslmode}\"\n",
    "    # Construct connection URI\n",
    "    return db_uri\n",
    "\n",
    "conn_string = get_connection_uri()\n",
    "\n",
    "conn = psycopg.connect(conn_string)\n",
    "\n",
    "# cursor pour ecrire dans la base\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion et recuperation des données depuis l'API\n",
    "url = 'https://data.nantesmetropole.fr/api/records/1.0/search/?dataset=244400404_fluidite-axes-routiers-nantes-metropole&rows=1000&timezone=Europe%2FParis'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# Transformer en DataFrame\n",
    "df = pd.json_normalize(data.get(\"records\", []))\n",
    "\n",
    "# renommer les colonne\n",
    "df.rename(columns={\n",
    "    'fields.cha_lib':'nom_du_tronçon',\n",
    "    'fields.cha_long': 'longueur',\n",
    "    'fields.mf1_taux': 'taux_occupation',\n",
    "    'fields.cha_id': 'id',\n",
    "    'fields.mf1_hd': 'horodatage',\n",
    "    'fields.mf1_debit' : 'debit',\n",
    "    'fields.mf1_vit' : 'vitesse',\n",
    "    'fields.tc1_temps': 'temps_de_parcours',\n",
    "    'fields.couleur_tp': 'code_couleur',\n",
    "    'fields.etat_trafic': 'etat_du_trafic',\n",
    "    'fields.geo_shape.coordinates': 'geometrie',\n",
    "    'fields.geo_point_2d': 'geo_point_2d',\n",
    "    'fields.geo_shape.type':'shape_geo',\n",
    "    'geometry.type':'type_geo',\n",
    "    'geometry.coordinates':'coordinates_geo'\n",
    "    \n",
    "}, inplace = True)\n",
    "\n",
    "# supprimer les colonnes inutiles\n",
    "df.drop(columns=['datasetid', 'recordid','record_timestamp'], inplace=True)\n",
    "\n",
    "# mettre id a la premiere position\n",
    "df = df[['id'] + [col for col in df.columns if col != 'id']]\n",
    "\n",
    "# Ajout d'un id technique qu'on mettre comme clé primaire dans notre BDD (pour eviter les doublons)\n",
    "df.insert(loc=0, column='id_technique',\n",
    "           value=df['id'].map(str) + '-' + df['horodatage'].apply(lambda x: x[0:19].replace('-', '').replace(':','')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données insérées avec succès !\n"
     ]
    }
   ],
   "source": [
    "# query pour ecrire dans la base\n",
    "query= \"\"\"\n",
    "    INSERT INTO public.trafic_routier\n",
    "(id, debit, longueur, taux_occupation, code_couleur, nom_du_troncon, etat_du_trafic, temps_de_parcours, vitesse, geo_point_2d, geometrie, shape_geo, horodatage, type_geo, coordinates_geo)\n",
    "VALUES(%s,%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# parcourir ligne par ligne le dataframe pour alimenter la base\n",
    "for row in df.itertuples(index=False):\n",
    "    cur.execute(query,\n",
    "                 (row.id_technique,row.id, row.debit, row.longueur, row.taux_occupation,\n",
    "                   row.code_couleur, row.nom_du_tronçon, row.etat_du_trafic\n",
    "                  , row.temps_de_parcours, row.vitesse, row.geo_point_2d, \n",
    "                  row.geometrie, row.shape_geo, row.horodatage,\n",
    "                    row.type_geo, row.coordinates_geo))\n",
    "    \n",
    "#confirmer les changement\n",
    "conn.commit()\n",
    "\n",
    "# Fermeture de la connexion\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_etude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
